/* SPDX-License-Identifier: GPL-2.0 */
/* X-SPDX-Copyright-Text: (c) Solarflare Communications Inc */

/**************************************************************************\
*//*! \file
** \brief     Additional Doxygen-format documentation for ef_vi.
*//*
\**************************************************************************/

/**************************************************************************
 * Worked Example page
 *************************************************************************/
/*! \page example Worked Example

This part of the documentation examines a simplified version of \ref
eflatency. This is a small application which listens for packets and
replies, with as low latency as possible.

This documentation discusses the tradeoffs that have been chosen, some
performance issues to avoid, and some possible additions that have been
omitted for clarity.

See also the supplied code for \ref eflatency , which includes many of
these improvements.

\section example_setup Setup

The first step is to set up %ef_vi:
- \#include the various headers we need (etherfabric/pd.h, vi.h, memreg.h)
- open the driver
- allocate a protection domain
- allocate a virtual interface from the protection domain.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~{.c}
ef_driver_handle  driver_handle;
ef_vi             vi;
ef_pd             pd;
static void do_init(int ifindex){
  ef_driver_open(&driver_handle);
  ef_pd_alloc(&pd, driver_handle, ifindex, EF_PD_DEFAULT );
  ef_vi_alloc_from_pd(&vi, driver_handle, &pd, driver_handle,
                      -1, -1, -1, NULL, -1, 0);
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The following improvements could be made:
- check the return values from these functions, in case the card has run
  out of resources and is unable to allocate more virtual interfaces
- offer physical buffer mode here.

\section example_buffers Creating Packet buffers

The next step is to allocate a memory region and register it for packet
buffers.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~{.c}
    const int BUF_SIZE = 2048;  /* Hardware always wants 2k buffers */
    int bytes = N_BUFS * BUF_SIZE;
    void* p;
    posix_memalign(&p, 4096, bytes)  /* allocate aligned memory */
    ef_memreg_alloc(&memreg, driver_handle, &pd, driver_handle,
	                p, bytes); /* Make it available to ef_vi */
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

This is all that is strictly necessary to set up the packet buffers.

However, the packet buffer is 2048 bytes long, whereas the normal MTU size
for a transmitted packet is only 1500 bytes. There is some spare memory in
each packet buffer. Performance can be improved by using this space to
cache some of the packet meta-data, so that it does not have to be
recalculated:

- The DMA address of the packet is cached. It is determined by getting the
  DMA address of the base of the memory chunk, and then incrementing in 2KB
  chunks.

- The packet ID is also cached.

A structure is used to store the cached meta-data and a few pointers in
the buffer. An array is used to track all the buffers:

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~{.c}
#define MEMBER_OFFSET(c_type, mbr_name) \
                     ((uint32_t) (uintptr_t)(&((c_type*)0)->mbr_name))
#define CACHE_ALIGN  __attribute__((aligned(EF_VI_DMA_ALIGN)))
struct pkt_buf {
  struct pkt_buf* next;
  /* We're not actually going to use this;
   * but chaining multiple buffers together is a common and useful trick. */
  ef_addr         dma_buf_addr;
  int             id;
  uint8_t         dma_buf[1] CACHE_ALIGN;
  /* Not strictly required, but cache aligning the payload is a speed
   * boost, so do it. */
};
/* We're also going to want to keep track of all our buffers, so have an
 * array of them.  Not strictly needed, but convenient.  */
    struct pkt_buf* pkt_bufs [N_BUFS];
    for( i = 0; i < N_BUFS; ++i ) {
      struct pkt_buf* pb = (struct pkt_buf*) ((char*) p + i * 2048);
      pb->id = i;
      pb->dma_buf_addr = ef_memreg_dma_addr(&memreg, i * 2048);
      pb->dma_buf_addr += MEMBER_OFFSET(struct pkt_buf, dma_buf);
      pkt_bufs[i] = pb;
    }
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

\note When receiving, the hardware will only fill up to 1824 bytes per
buffer. Larger jumbo frames are split across multiple buffers.

\section example_filters Adding Filters

Next, a filter is specified and added, so that the virtual interface
receives traffic. Assuming there is a sockaddr to work from:

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~{.c}
  struct sockaddr_in sa_local;  /* TODO: Fill this out somehow */
  ef_filter_spec filter_spec;
  ef_filter_spec_init(&filter_spec, EF_FILTER_FLAG_NONE);
  TRY(ef_filter_spec_set_ip4_local(&filter_spec, IPPROTO_UDP,
                                   sa_local.sin_addr.s_addr,
                                   sa_local.sin_port));
  TRY(ef_vi_filter_add(&vi, driver_handle, &filter_spec, NULL));
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

\section example_receive Receiving packets

At this point, packets will start arriving at the interface, be diverted
to the application, and immediately be dropped.

So the next step is to push some packet buffers to the RX descriptor ring,
to receive the incoming packets.

For efficiency, the code pushes packet buffers eight at a time.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~{.c}
unsigned rx_posted = 0;  /* We need to keep track of which buffers are
                          * already on the ring */
void rx_post( int n ) {
  for( int i = 0; i < n; ++i ) {
    struct pkt_buf* pb = pkt_bufs[rx_posted % N_RX_BUFS];
    ef_vi_receive_init(&vi, pb->dma_buf_addr, pb->id);
    ++rx_posted;
  }
  ef_vi_receive_push(&vi);

}
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

So now, there are packet buffers on the descriptor ring. But once they are
filled, the application will start dropping again.

\section example_events Handling Events

The next step is to handle these incoming packets, by polling the event
queue.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~{.c}
void rx_wait(void) {
  /* Again, for efficiency, poll multiple events at once.  */
  ef_event      evs[NUM_POLL_EVENTS];
  int           n_ev, i;

  while( 1 ) {
    n_ev = ef_eventq_poll(&vi, evs, NUM_POLL_EVENTS);
    if( n_ev > 0 )
      for( i = 0; i < n_ev; ++i )
        switch( EF_EVENT_TYPE(evs[i]) ) {
        case EF_EVENT_TYPE_RX:
          handle_rx_packet(EF_EVENT_RX_RQ_ID(evs[i]),
                           EF_EVENT_RX_BYTES(evs[i]) );
          break;
        case EF_EVENT_TYPE_RX_DISCARD:
          /* Interesting to print out the cause of the discard */
          fprintf(stderr, "ERROR: RX_DISCARD type=%d",
                  EF_EVENT_RX_DISCARD_TYPE(evs[i]));
          /* but let's handle it like a normal packet anyway */
          handle_rx_packet(EF_EVENT_RX_RQ_ID(evs[i]),
                           EF_EVENT_RX_BYTES(evs[i]) );
          break;
} } }
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

This code is calling a `handle_rx_packet()` function, passing it the
packet id (which corresponds directly to the `pkt_bufs` array - see \ref
example_buffers) and the length of data. The body of this function is not
shown, but it should do the following:

- note that this packet buffer has been consumed, and so is ready to be
  re-posted:

  - the `rx_post()` function(see \ref example_receive) must also be
    updated to use this information, so a buffer is not re-posted until it
    is marked as consumed

- ensure that the received packet is processed according to the purpose of
  the application:

  - if the application can always process incoming packets as fast as they
    are received, then it can do its work inline, and immediately repost
	the buffer on the ring

  - otherwise, the application should probably post an item on a work
    queue for another thread to act upon, and arrange for the refill to
	come from a larger pool of buffers

- optionally, handle discards in some different way (perhaps not raising
  the work event).

\section example_transmit Transmitting packets

The next step is to implement the transmit side. The hard part is filling
out the payload, and getting all the fields of IP and UDP correct. (%ef_vi
is usually used to transmit UDP, as it's a much simpler protocol to
implement than TCP.)

There's some sample code to fill out the headers in the functions
`ci_*_hdr_init()`, which can be found in `src/lib/citools/ippacket.c`.

After that, to transmit one of the `pb` structures (see \ref
example_buffers), a single function call is needed:

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~{.c}
ef_vi_transmit(&vi, pb->dma_buf_addr, frame_length, 0);
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

But the application must also keep track of when that buffer is used, and
when it is free. This means adding some complexity to the poll loop (see
\ref example_events). The absolute minimum is:

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~{.c}
        case EF_EVENT_TYPE_TX:
          ef_vi_transmit_unbundle(&vi, &evs[i], ids);
          break;
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

This is only sufficient if the TX buffers and the RX buffers are from
different pools.

\note In ping pong there is only ever one outstanding send. The
application does not transmit another packet until the remote side has
processed the current one, and so the application does not even need to
keep track of its state.

One option would be to free up sent buffers, to a pool ready to be filled
with data.  Other applications may instead fill a few packet buffers with
data, and then transmit them as and when, only keeping track to make sure
that the TX ring never overfills.

*/